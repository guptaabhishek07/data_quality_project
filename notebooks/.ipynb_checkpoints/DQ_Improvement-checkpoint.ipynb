{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d00933-c34a-4045-9c35-e35d3c1f9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9424728-bc0f-45ea-b57f-31db64107de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/Users/abhishekkumar/Desktop/data_quality_project/data1\"\n",
    "cleaned_folder = \"/Users/abhishekkumar/Desktop/data_quality_project/cleaned_data\"\n",
    "os.makedirs(cleaned_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a16603f-368c-432e-b18d-0f0fbed5eaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "all_files = [f for f in os.listdir(data_folder) if f.endswith(('.json', '.jsonl'))]\n",
    "dfs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebefa236-a068-43f4-bd1f-0a315c152ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[f] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d35c7764-6168-4e7d-9e95-5e130d826d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25641 entries, 0 to 25653\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   data      25641 non-null  object\n",
      " 1   included  25641 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83ff871e-2118-4395-85ba-3ba034c5a3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>included</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25641</td>\n",
       "      <td>25641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>25641</td>\n",
       "      <td>24820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>[{'id': '45bbf6ee-348a-4ea6-8f1d-e453c1ecfe96'...</td>\n",
       "      <td>[{'id': 'd911f2fa-646c-5d15-bd61-eaf59ef68379'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     data  \\\n",
       "count                                               25641   \n",
       "unique                                              25641   \n",
       "top     [{'id': '45bbf6ee-348a-4ea6-8f1d-e453c1ecfe96'...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                 included  \n",
       "count                                               25641  \n",
       "unique                                              24820  \n",
       "top     [{'id': 'd911f2fa-646c-5d15-bd61-eaf59ef68379'...  \n",
       "freq                                                    5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922a0c71-a1d8-4d89-89bd-f557385b828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 datasets.\n"
     ]
    }
   ],
   "source": [
    "for f in all_files:\n",
    "    file_path = os.path.join(data_folder, f)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "    df = pd.json_normalize(data)\n",
    "    df_dedup = df.astype(str).drop_duplicates()  # initial deduplication\n",
    "    dfs[f] = df_dedup\n",
    "\n",
    "print(f\"Loaded {len(dfs)} datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b1dc07-b365-4694-ba8f-493333deb5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs = {}\n",
    "cleaning_summary = []\n",
    "\n",
    "for file_name, df in dfs.items():\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # --- Remove rows with missing critical values ---\n",
    "    if 'headline' in df_clean.columns:\n",
    "        df_clean = df_clean[df_clean['headline'].notnull()]\n",
    "    \n",
    "    # --- Remove duplicate rows ---\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    \n",
    "    # --- Standardize text columns ---\n",
    "    for col in df_clean.select_dtypes(include='object').columns:\n",
    "        df_clean[col] = df_clean[col].str.strip().str.title()  # normalize capitalization\n",
    "    \n",
    "    # --- Standardize dates ---\n",
    "    if 'event_date' in df_clean.columns:\n",
    "        df_clean['event_date'] = pd.to_datetime(df_clean['event_date'], errors='coerce')\n",
    "    \n",
    "    # --- Correct numeric outliers using IQR ---\n",
    "    numeric_cols = df_clean.select_dtypes(include=['int64','float64']).columns\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df_clean[col] = df_clean[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    # --- Categorical consistency: encode and normalize categories ---\n",
    "    cat_cols = df_clean.select_dtypes(include='object').columns\n",
    "    for col in cat_cols:\n",
    "        df_clean[col] = df_clean[col].astype(str)\n",
    "        df_clean[col] = df_clean[col].str.replace(r'[^A-Za-z0-9\\s]', '', regex=True)  # remove special chars\n",
    "        df_clean[col] = df_clean[col].str.replace(r'\\s+', ' ', regex=True)  # unify spaces\n",
    "    \n",
    "    cleaned_dfs[file_name] = df_clean\n",
    "    \n",
    "    # --- Document before/after metrics ---\n",
    "    summary = {\n",
    "        'file': file_name,\n",
    "        'raw_rows': df.shape[0],\n",
    "        'cleaned_rows': df_clean.shape[0],\n",
    "        'removed_rows': df.shape[0] - df_clean.shape[0],\n",
    "        'raw_duplicates': df.duplicated().sum(),\n",
    "        'cleaned_duplicates': df_clean.duplicated().sum(),\n",
    "        'raw_missing_headline': df['headline'].isnull().sum() if 'headline' in df.columns else 0,\n",
    "        'clean_missing_headline': df_clean['headline'].isnull().sum() if 'headline' in df_clean.columns else 0\n",
    "    }\n",
    "    cleaning_summary.append(summary)\n",
    "    \n",
    "    # --- Save cleaned dataset ---\n",
    "    save_path = os.path.join(cleaned_folder, file_name.replace('.jsonl', '_cleaned.jsonl'))\n",
    "    df_clean.to_json(save_path, orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e503b64c-f250-4bd0-8f6b-9608ad2aa781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 4 Enhanced completed. Cleaned files saved.\n",
      "Cleaning summary saved at: /Users/abhishekkumar/Desktop/data_quality_project/cleaned_data/Phase4_Cleaning_Summary_Enhanced.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>raw_rows</th>\n",
       "      <th>cleaned_rows</th>\n",
       "      <th>removed_rows</th>\n",
       "      <th>raw_duplicates</th>\n",
       "      <th>cleaned_duplicates</th>\n",
       "      <th>raw_missing_headline</th>\n",
       "      <th>clean_missing_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news_events_2025_07_07.00086.jsonl</td>\n",
       "      <td>26131</td>\n",
       "      <td>26131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news_events_2025_07_07.00003.jsonl</td>\n",
       "      <td>25400</td>\n",
       "      <td>25400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news_events_2025_07_07.00001.jsonl</td>\n",
       "      <td>25922</td>\n",
       "      <td>25922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news_events_2025_07_07.00084.jsonl</td>\n",
       "      <td>25644</td>\n",
       "      <td>25644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news_events_2025_07_07.00005.jsonl</td>\n",
       "      <td>26185</td>\n",
       "      <td>26185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file  raw_rows  cleaned_rows  removed_rows  \\\n",
       "0  news_events_2025_07_07.00086.jsonl     26131         26131             0   \n",
       "1  news_events_2025_07_07.00003.jsonl     25400         25400             0   \n",
       "2  news_events_2025_07_07.00001.jsonl     25922         25922             0   \n",
       "3  news_events_2025_07_07.00084.jsonl     25644         25644             0   \n",
       "4  news_events_2025_07_07.00005.jsonl     26185         26185             0   \n",
       "\n",
       "   raw_duplicates  cleaned_duplicates  raw_missing_headline  \\\n",
       "0               0                   0                     0   \n",
       "1               0                   0                     0   \n",
       "2               0                   0                     0   \n",
       "3               0                   0                     0   \n",
       "4               0                   0                     0   \n",
       "\n",
       "   clean_missing_headline  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---  Create cleaning summary DataFrame ---\n",
    "summary_df = pd.DataFrame(cleaning_summary)\n",
    "summary_excel_path = os.path.join(cleaned_folder, \"Phase4_Cleaning_Summary_Enhanced.xlsx\")\n",
    "summary_df.to_excel(summary_excel_path, index=False)\n",
    "\n",
    "print(\"Phase 4 Enhanced completed. Cleaned files saved.\")\n",
    "print(f\"Cleaning summary saved at: {summary_excel_path}\")\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26398716-fc20-4ac4-8f7a-3e4fabcd01c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>included</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id 49C2548F7A5B45E39Bbc84477E7Fd0D0 Type NewsE...</td>\n",
       "      <td>Id 5C5Eebf036415525B95AEa2B75E0E508 Type Compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Id 49C25F6FEf44406EBa5437B4530E1642 Type NewsE...</td>\n",
       "      <td>Id C9B92FfdA2Ed57878B06F4Bf8D291E57 Type Compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Id 49C9867F4C204Be9B11AE7B8C9A71Ccb Type NewsE...</td>\n",
       "      <td>Id Af50948AE2B355B885C46A9881A55Ec2 Type Compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Id 49Cd397D1Fa64C20Beb5622D9Ec185C3 Type NewsE...</td>\n",
       "      <td>Id Caa07793A6E65E1284C8C6F88E68A965 Type Compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Id 49D417D9279845CbA20852Ed65329797 Type NewsE...</td>\n",
       "      <td>Id 3Bdf4A7591D854B39C8AD626B1A12864 Type Compa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  Id 49C2548F7A5B45E39Bbc84477E7Fd0D0 Type NewsE...   \n",
       "1  Id 49C25F6FEf44406EBa5437B4530E1642 Type NewsE...   \n",
       "2  Id 49C9867F4C204Be9B11AE7B8C9A71Ccb Type NewsE...   \n",
       "3  Id 49Cd397D1Fa64C20Beb5622D9Ec185C3 Type NewsE...   \n",
       "4  Id 49D417D9279845CbA20852Ed65329797 Type NewsE...   \n",
       "\n",
       "                                            included  \n",
       "0  Id 5C5Eebf036415525B95AEa2B75E0E508 Type Compa...  \n",
       "1  Id C9B92FfdA2Ed57878B06F4Bf8D291E57 Type Compa...  \n",
       "2  Id Af50948AE2B355B885C46A9881A55Ec2 Type Compa...  \n",
       "3  Id Caa07793A6E65E1284C8C6F88E68A965 Type Compa...  \n",
       "4  Id 3Bdf4A7591D854B39C8AD626B1A12864 Type Compa...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.head()  # Review metrics\n",
    "cleaned_dfs['news_events_2025_07_07.00086.jsonl'].head()  # Check cleaned data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b42cd13-cb6b-446d-a911-904a2f62eb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286f32e-9461-4987-aee8-9ce77acfa312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7d91e-82a5-49ef-85bc-d1bc7bbe6b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289a752a-4bac-42a6-843e-9f29bcf7a1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc83cdc-0028-40dc-b5bf-1da91660ab8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
