{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec986d7-ba94-4737-b7d2-993f0a2a959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f8fee7-e578-4919-a50c-3a8d0d70ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Configuration ----------\n",
    "data_folder = \"/Users/abhishekkumar/Desktop/data_quality_project/cleaned_data\"\n",
    "db_path = \"news_events_dq.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a571d25c-6648-4d8e-84fb-5f9817622419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Connect to SQLite ----------\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "895abad7-988e-4e07-83e0-117d0f6d691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Create Tables ----------\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS news_events (\n",
    "    id TEXT PRIMARY KEY,\n",
    "    headline TEXT NOT NULL,\n",
    "    event_date DATE,\n",
    "    category TEXT,\n",
    "    source TEXT,\n",
    "    summary TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS data_quality_metrics (\n",
    "    file_name TEXT NOT NULL,\n",
    "    metric_date DATE NOT NULL,\n",
    "    total_rows INTEGER,\n",
    "    missing_rows INTEGER,\n",
    "    duplicate_rows INTEGER,\n",
    "    invalid_headlines INTEGER,\n",
    "    future_dates INTEGER\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "368724ba-d5e0-4332-8987-76f5fbe185fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "near \")\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m     invalid_headlines \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheadline\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotnull(x) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Insert into news_events\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m df\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_events\u001b[39m\u001b[38;5;124m'\u001b[39m, conn, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Insert DQ metrics into data_quality_metrics\u001b[39;00m\n\u001b[1;32m     39\u001b[0m cursor\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124mINSERT INTO data_quality_metrics \u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124m(file_name, metric_date, total_rows, missing_rows, duplicate_rows, invalid_headlines, future_dates)\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     future_dates\n\u001b[1;32m     51\u001b[0m ))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2891\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3083\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[0;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[1;32m   3088\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3089\u001b[0m     name,\n\u001b[1;32m   3090\u001b[0m     con,\n\u001b[1;32m   3091\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m   3092\u001b[0m     if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[1;32m   3093\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   3094\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m   3095\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   3096\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   3097\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   3098\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/sql.py:842\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    839\u001b[0m     )\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[1;32m    843\u001b[0m         frame,\n\u001b[1;32m    844\u001b[0m         name,\n\u001b[1;32m    845\u001b[0m         if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[1;32m    846\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m    847\u001b[0m         index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m    848\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m    849\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    850\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    851\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    852\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m    853\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[1;32m    854\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/sql.py:2851\u001b[0m, in \u001b[0;36mSQLiteDatabase.to_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   2841\u001b[0m table \u001b[38;5;241m=\u001b[39m SQLiteTable(\n\u001b[1;32m   2842\u001b[0m     name,\n\u001b[1;32m   2843\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2848\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   2849\u001b[0m )\n\u001b[1;32m   2850\u001b[0m table\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[0;32m-> 2851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39minsert(chunksize, method)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/sql.py:1119\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[0;34m(self, chunksize, method)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m chunk_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[0;32m-> 1119\u001b[0m num_inserted \u001b[38;5;241m=\u001b[39m exec_insert(conn, keys, chunk_iter)\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_inserted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/sql.py:2547\u001b[0m, in \u001b[0;36mSQLiteTable._execute_insert\u001b[0;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_execute_insert\u001b[39m(\u001b[38;5;28mself\u001b[39m, conn, keys, data_iter) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   2546\u001b[0m     data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data_iter)\n\u001b[0;32m-> 2547\u001b[0m     conn\u001b[38;5;241m.\u001b[39mexecutemany(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minsert_statement(num_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), data_list)\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mrowcount\n",
      "\u001b[0;31mOperationalError\u001b[0m: near \")\": syntax error"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Load cleaned JSONL files and compute DQ metrics ----------\n",
    "all_files = [f for f in os.listdir(data_folder) if f.endswith('.jsonl')]\n",
    "\n",
    "for file_name in all_files:\n",
    "    file_path = os.path.join(data_folder, file_name)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    \n",
    "    if not data:\n",
    "        continue\n",
    "    \n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Keep only relevant columns\n",
    "    columns_to_keep = ['id', 'headline', 'event_date', 'category', 'source', 'summary']\n",
    "    df = df[[col for col in columns_to_keep if col in df.columns]]\n",
    "    \n",
    "    # Convert event_date to date\n",
    "    if 'event_date' in df.columns:\n",
    "        df['event_date'] = pd.to_datetime(df['event_date'], errors='coerce').dt.date\n",
    "    \n",
    "    # ----- Phase 3 Data Quality Metrics -----\n",
    "    total_rows = df.shape[0]\n",
    "    total_missing = df.isnull().sum().sum()\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    "    \n",
    "    future_dates = 0\n",
    "    if 'event_date' in df.columns:\n",
    "        future_dates = (pd.to_datetime(df['event_date'], errors='coerce') > pd.Timestamp.today()).sum()\n",
    "    \n",
    "    invalid_headlines = 0\n",
    "    if 'headline' in df.columns:\n",
    "        invalid_headlines = df['headline'].apply(lambda x: not bool(str(x).strip()) if pd.notnull(x) else True).sum()\n",
    "    \n",
    "    # Insert into news_events\n",
    "    df.to_sql('news_events', conn, if_exists='append', index=False)\n",
    "    \n",
    "    # Insert DQ metrics into data_quality_metrics\n",
    "    cursor.execute(\"\"\"\n",
    "    INSERT INTO data_quality_metrics \n",
    "    (file_name, metric_date, total_rows, missing_rows, duplicate_rows, invalid_headlines, future_dates)\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", (\n",
    "        file_name,\n",
    "        datetime.today().date(),\n",
    "        total_rows,\n",
    "        total_missing,\n",
    "        duplicate_rows,\n",
    "        invalid_headlines,\n",
    "        future_dates\n",
    "    ))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(\"All files loaded with Data Quality metrics successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08091971-10e6-4256-8b49-6e9bd56717ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086a90e-c284-4232-9f71-42dfcdd25ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f309e2-e273-4577-840a-55d563a5aa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded84fe1-856d-4b4e-bb16-60aec882c8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608935e6-79b3-4606-8e6f-ab528539eb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ba6813-ccd5-4bf7-9039-abccd2eda1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae70976-99ff-47cd-981d-f3f839444c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e95601-2dbc-4f31-8807-1e6dbbb71837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8293cb-f927-4ef9-9ccf-e734845a0a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea394f93-3152-45e1-a93e-c72ba23809b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e229742-43e2-4ca0-91b8-bfbb3b813da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4fae52-08dd-4328-9aa4-3a7dcc10ef66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
